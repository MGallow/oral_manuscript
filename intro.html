<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 1 Introduction | Shrinking Characteristics of Precision Matrix Estimators: An Illustration via Regression</title>
  <meta name="description" content="Matt Galloway’s Master’s thesis.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 1 Introduction | Shrinking Characteristics of Precision Matrix Estimators: An Illustration via Regression" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://mattxgalloway.com/oral_manuscript/" />
  
  <meta property="og:description" content="Matt Galloway’s Master’s thesis." />
  <meta name="github-repo" content="MGallow/oral_manuscript" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction | Shrinking Characteristics of Precision Matrix Estimators: An Illustration via Regression" />
  
  <meta name="twitter:description" content="Matt Galloway’s Master’s thesis." />
  

<meta name="author" content="Matt Galloway">


<meta name="date" content="2019-04-29">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="precision-matrix-estimation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Matt Galloway Oral Manuscript</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="precision-matrix-estimation.html"><a href="precision-matrix-estimation.html"><i class="fa fa-check"></i><b>2</b> Precision Matrix Estimation</a><ul>
<li class="chapter" data-level="2.1" data-path="precision-matrix-estimation.html"><a href="precision-matrix-estimation.html#background"><i class="fa fa-check"></i><b>2.1</b> Background</a></li>
<li class="chapter" data-level="2.2" data-path="precision-matrix-estimation.html"><a href="precision-matrix-estimation.html#admm-algorithm"><i class="fa fa-check"></i><b>2.2</b> ADMM Algorithm</a></li>
<li class="chapter" data-level="2.3" data-path="precision-matrix-estimation.html"><a href="precision-matrix-estimation.html#simulations"><i class="fa fa-check"></i><b>2.3</b> Simulations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="scpme.html"><a href="scpme.html"><i class="fa fa-check"></i><b>3</b> SCPME</a><ul>
<li class="chapter" data-level="3.1" data-path="scpme.html"><a href="scpme.html#augmented-admm-algorithm"><i class="fa fa-check"></i><b>3.1</b> Augmented ADMM Algorithm</a></li>
<li class="chapter" data-level="3.2" data-path="scpme.html"><a href="scpme.html#regression-illustration"><i class="fa fa-check"></i><b>3.2</b> Regression Illustration</a></li>
<li class="chapter" data-level="3.3" data-path="scpme.html"><a href="scpme.html#simulations-1"><i class="fa fa-check"></i><b>3.3</b> Simulations</a></li>
<li class="chapter" data-level="3.4" data-path="scpme.html"><a href="scpme.html#discussion"><i class="fa fa-check"></i><b>3.4</b> Discussion</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a></li>
<li class="chapter" data-level="B" data-path="admmsigma-r-package.html"><a href="admmsigma-r-package.html"><i class="fa fa-check"></i><b>B</b> <code>ADMMsigma</code> R Package</a><ul>
<li class="chapter" data-level="B.1" data-path="admmsigma-r-package.html"><a href="admmsigma-r-package.html#installation"><i class="fa fa-check"></i><b>B.1</b> Installation</a></li>
<li class="chapter" data-level="B.2" data-path="admmsigma-r-package.html"><a href="admmsigma-r-package.html#tutorial"><i class="fa fa-check"></i><b>B.2</b> Tutorial</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="scpme-r-package.html"><a href="scpme-r-package.html"><i class="fa fa-check"></i><b>C</b> <code>SCPME</code> R Package</a><ul>
<li class="chapter" data-level="C.1" data-path="scpme-r-package.html"><a href="scpme-r-package.html#installation-1"><i class="fa fa-check"></i><b>C.1</b> Installation</a></li>
<li class="chapter" data-level="C.2" data-path="scpme-r-package.html"><a href="scpme-r-package.html#tutorial-1"><i class="fa fa-check"></i><b>C.2</b> Tutorial</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Shrinking Characteristics of Precision Matrix Estimators: An Illustration via Regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<p>Inferential statistics consists of two primary components: estimation and prediction. Estimation refers to the process by which we infer values, properties and behavior about individual parameters in our model. Prediction, on the other hand, refers to the process by which we draw inference about an event that has not-yet occurred. The latter component is abundant in industry where the demand to predict stock prices, movies individuals prefer, and even to predict new friend connections in a network has sparked huge investments in research and given rise to research groups whose primary goal is pushing the bounds and developing new predictive models.</p>
<p>However, though most attention is directed towards prediction, these two components are not distinct. In fact, the success and reliability of many predictive models is contingent upon good, efficient parameter estimation. Many of these models require the estimation of a precision matrix - the inverse of the covariance matrix (frequently denoted as <span class="math inline">\(\Omega\)</span>) - that establishes the interaction and covariance between random variables. For this reason, the last decade has seen an ever-expanding community devoted to precision matrix estimation.</p>
<p>Among this community of researchers is Professor Adam Rothman and Aaron Molstad, Ph.D. whose research will be a focal point of this manuscript. The two have published work on indirect multivariate linear regression (<span class="citation">Molstad and Rothman (<a href="#ref-molstad2016indirect">2016</a>)</span>) and classification with matrix-valued predictors (<span class="citation">Molstad and Rothman (<a href="#ref-molstad2018penalized">2018</a>)</span>) but the focus of this manuscript is their 2017 paper titled <em>Shrinking Characteristics of Precision Matrix Estimators</em> (<span class="citation">Molstad and Rothman (<a href="#ref-molstad2017shrinking">2017</a>)</span>). In it, they outline a framework to estimate <em>characteristics</em> of precision matrices - a concept that exploits the fact that in many predictive models estimation of the precision matrix is only necessary through its product with another feature. They write in their manuscript that “to fit many predictive models, only a characteristic of the population precision matrix needs to be estimated… In binary linear discriminant analysis, the population precision matrix is needed for prediction only through the product of the precision matrix and the difference between the two conditional distribution mean vectors.” The purpose of the research detailed here began with the desire to expand on this concept and to explore avenues that were mentioned but were not further investigated.</p>
<p>One of the research directions mentioned in the original paper was the application of their framework to regression. Utilizing the fact that the population regression coefficient matrix <span class="math inline">\(\beta \equiv \Omega_{x}\Sigma_{xy}\)</span> (where <span class="math inline">\(\Sigma_{xy}\)</span> is the cross-covariance matrix between the predictors, <span class="math inline">\(X\)</span>, and the responses, <span class="math inline">\(Y\)</span>, and <span class="math inline">\(\Omega_{x}\)</span> is the precision matrix for <span class="math inline">\(X\)</span>), their framework allows for the simultaneous estimation of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\Omega_{x}\)</span> with an embedded assumption potentially useful for superior prediction performance. In close communication and collaboration with Professor Rothman, we wanted to explore this research direction further. However, in order to build upon their work and contribute new material, there were a number of concepts that needed to be learned along the way and this document will follow that journey.</p>
<p>We will begin chapter two with a brief introduction to precision matrix estimation and the gaussian log-likelihood function. This section will mention popular estimation methods and algorithms but most discussion will be directed towards the ADMM algorithm. Discussion of the ADMM algorithm will be useful as we begin detailing the shrinking characteristics of precision matrix estimators framework (which may be referred to as SCPME), the so-called augmented ADMM algorithm, and later the framework’s application to regression. Lastly, the document will end with two brief tutorials for the R packages <code>ADMMsigma</code> and <code>SCPME</code>. These packages were developed by myself to aid in simulation experiments and make it easier to branch into related research directions. Both packages have since been published on CRAN.</p>
<div id="notation-and-definitions" class="section level3">
<h3><span class="header-section-number">1.0.1</span> Notation and Definitions</h3>
<p>For strictly positive integers <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>, we will denote <span class="math inline">\(\mathbb{R}^{n \times p}\)</span> as the class of real matrices with dimenson <span class="math inline">\(n \times p\)</span>. The class of real, symmetric matrices with dimension <span class="math inline">\(p \times p\)</span> will be denoted as <span class="math inline">\(\mathbb{S}^{p}\)</span> and <span class="math inline">\(\mathbb{S}^{p}_{+}\)</span> if we further require the object to be positive definite. The sample size and dimension of the predictor vector in a given data set will most often be denoted as <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>, respectively. If the dimension of the response vector exceeds one, we will denote it as <span class="math inline">\(r\)</span>.</p>
<p>Most matrices will take the form of either <span class="math inline">\(\Sigma\)</span>, the population covariance matrix, or <span class="math inline">\(\Omega\)</span>, the population precision matrix. Note that the precision matrix is simply the inverse of the covariance matrix (<span class="math inline">\(\Omega \equiv \Sigma^{-1}\)</span>) and a subscript may be added to each if more than two random variables are considered in a problem (<span class="math inline">\(\Omega_{x}\)</span>). A subscript star may also be added if the object is oracle - or known - a priori (<span class="math inline">\(\Omega_{*}\)</span>). The oracle’s estimator that optimizes a pre-specified objective function will be denoted with a hat (<span class="math inline">\(\hat{\Omega}\)</span>).</p>
<p>There will be significant matrix algebra notation throughout the manuscript. The trace operator sums the diagonal elements of a matrix and will take the form <span class="math inline">\(tr\left(\cdot\right)\)</span> and the <em>exponential</em> trace operator will be denoted similarly as <span class="math inline">\(etr\left(\cdot\right)\)</span>. The vector operator, <span class="math inline">\(vec\left(\cdot\right)\)</span>, stacks the columns of a matrix into a column vector. The determinant of a matrix <span class="math inline">\(\mathbf{A}\)</span> will be denoted as <span class="math inline">\(\left|\mathbf{A}\right|\)</span> but may also take the form <span class="math inline">\(det\left(\mathbf{A}\right)\)</span>. The kronecker product of two matrices <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> will be denoted as <span class="math inline">\(\mathbf{A} \otimes \mathbf{B}\)</span> and the element-wise product will be denoted as <span class="math inline">\(\mathbf{A} \circ \mathbf{B}\)</span>. Lastly, the Frobenius norm which sums the square of all entries in a matrix will be denoted as <span class="math inline">\(\left\|\mathbf{A}\right\|_{F}\)</span> and we will define <span class="math inline">\(\left\|\mathbf{A}\right\|_{1} := \sum_{i, j}\left|\mathbf{A}_{ij}\right|\)</span> where the <span class="math inline">\(i\)</span>-<span class="math inline">\(j\)</span>th element in matrix <span class="math inline">\(\mathbf{A}\)</span> is typically denoted as <span class="math inline">\(\left(\mathbf{A}\right)_{ij}\)</span> or simply <span class="math inline">\(\mathbf{A}_{ij}\)</span>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-molstad2016indirect">
<p>Molstad, Aaron J, and Adam J Rothman. 2016. “Indirect Multivariate Response Linear Regression.” <em>Biometrika</em> 103 (3). Oxford University Press: 595–607.</p>
</div>
<div id="ref-molstad2018penalized">
<p>Molstad, Aaron J, and Adam J Rothman. 2018. “A Penalized Likelihood Method for Classification with Matrix-Valued Predictors.” <em>Journal of Computational and Graphical Statistics</em>. Taylor &amp; Francis, 1–12.</p>
</div>
<div id="ref-molstad2017shrinking">
<p>Molstad, Aaron J, and Adam J Rothman. 2017. “Shrinking Characteristics of Precision Matrix Estimators.” <em>Biometrika</em>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="precision-matrix-estimation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/MGallow/oral_manuscript/edit/master/01-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Manuscript.pdf", "Manuscript.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
