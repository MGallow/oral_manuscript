
# Penalized Regression Estimators

This document explores a number of regression estimators subject to various assumptions. We will assume $n$ samples of

\[ Y_{i} = \mu_{y} + \beta^{T}(X_{i} - \mu_{x}) + \epsilon_{i} \]

where $\epsilon_{i} \sim N_{r}\left(0, \Sigma_{y | x} \right)$ and $X_{i} \sim N_{p}\left(0, \Sigma_{x}\right)$ so that by taking $\theta = \left( \mu_{y}, \mu_{x}, vec\left( \beta \right), vec\left( \Sigma_{y | x}^{-1} \right), vec\left( \Sigma_{xx}^{-1} \right) \right)^{T}$ the joint log-likelihood is of the following form:

\begin{align*}
  l(\theta) &= \frac{nr}{2}log(2\pi) - \frac{n}{2}log\left| \Sigma_{y | x}^{-1} \right| + \frac{1}{2}\sum_{i = 1}^{n}\left( Y_{i} - \mu_{y} - \beta^{T}\left( X_{i} - \mu_{x} \right) \right)^{T}\Sigma_{y | x}^{-1}\left( Y_{i} - \mu_{y} - \beta^{T}\left( X_{i} - \mu_{x} \right) \right) \\
  &+ \frac{np}{2}log(2\pi) - \frac{n}{2}log\left| \Sigma_{xx}^{-1} \right| + \frac{1}{2}\sum_{i = 1}^{n}\left( X_{i} - \mu_{x} \right)^{T}\Sigma_{xx}^{1}\left( X_{i} - \mu_{x} \right) \\
\end{align*}

For convenience, we will later denote $\mathbb{X}$ as the $n \times p$ matrix with rows $X_{i} - \bar{X}$ where $\bar{X} = \sum_{i = 1}^{n}X_{i}/n$ and $\mathbb{Y}$ as the $n \times r$ matrix with rows $Y_{i} - \bar{Y}$ and $\bar{Y}$ defined similarly. Note that $\bar{X}$ and $\bar{Y}$ are the maximum likelihood esitmators of $\mu_{x}$ and $\mu_{y}$, respectively.


## Formulas

Below we outline a few important formulas that will be used throughout this report:

\vspace{0.5cm}

1. Forward regression coefficient: $\beta = \Sigma_{xx}^{-1}\Sigma_{xy} = \Sigma_{x | y}^{-1}\alpha^{T}\left( \Sigma_{yy}^{-1} + \alpha\Sigma_{x | y}^{-1}\alpha^{T} \right)^{-1}$

\vspace{0.5cm}

2. Inverse regression coefficient: $\alpha = \Sigma_{yy}^{-1}\Sigma_{xy}^{T}$

\vspace{0.5cm}

3. $\Sigma_{y | x} = \Sigma_{yy} - \beta^{T}\Sigma_{xx}\beta = \Sigma_{yy} - \Sigma_{xy}^{T}\Sigma_{xx}^{-1}\Sigma_{xy}$

\vspace{0.5cm}

4. $\Sigma_{y | x}^{-1} = \Sigma_{yy}^{-1} + \Sigma_{y | x}^{-1}\Sigma_{xy}^{T}\left( \Sigma_{yy} + \Sigma_{xy}\Sigma_{y | x}^{-1}\Sigma_{xy}^{T} \right)^{-1}\Sigma_{xy}\Sigma_{y | x}^{-1} = \Sigma_{yy}^{-1} + \Sigma_{y | x}^{-1}\beta\left( \Sigma_{xx}^{-1} + \beta\Sigma_{y | x}^{-1}\beta^{T} \right)^{-1}\beta\Sigma_{y | x}^{-1}$

\vspace{0.5cm}

5. $\Sigma_{x | y} = \Sigma_{xx} - \alpha^{T}\Sigma_{yy}\alpha = \Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{xy}^{T}$

\vspace{0.5cm}

6. $\Sigma_{x | y}^{-1} = \Sigma_{xx}^{-1} + \Sigma_{x | y}^{-1}\Sigma_{xy}\left( \Sigma_{yy} + \Sigma_{xy}^{T}\Sigma_{x | y}^{-1}\Sigma_{xy} \right)^{-1}\Sigma_{xy}^{T}\Sigma_{x | y}^{-1} = \Sigma_{xx}^{-1} + \Sigma_{x | y}^{-1}\alpha\left( \Sigma_{yy}^{-1} + \alpha\Sigma_{x | y}^{-1}\alpha^{T} \right)^{-1}\alpha\Sigma_{x | y}^{-1}$

\vspace{0.5cm}

7. $\Sigma_{yy}^{-1} = \Sigma_{y | x}^{-1} - \Sigma_{y | x}^{-1}\Sigma_{xy}^{T}\left( \Sigma_{xx} + \Sigma_{xy}\Sigma_{y | x}^{-1}\Sigma_{xy}^{T} \right)^{-1}\Sigma_{xy}\Sigma_{y | x}^{-1} = \Sigma_{y | x}^{-1} - \Sigma_{y | x}^{-1}\beta\left( \Sigma_{xx}^{-1} + \beta\Sigma_{y | x}^{-1}\beta^{T} \right)^{-1}\beta\Sigma_{y | x}^{-1}$

\vspace{0.5cm}

8. $\Sigma_{xx}^{-1} = \Sigma_{x | y}^{-1} - \Sigma_{x | y}^{-1}\Sigma_{xy}\left( \Sigma_{yy} + \Sigma_{xy}^{T}\Sigma_{x | y}^{-1}\Sigma_{xy} \right)^{-1}\Sigma_{xy}^{T}\Sigma_{x | y}^{-1} = \Sigma_{x | y}^{-1} - \Sigma_{x | y}^{-1}\alpha\left( \Sigma_{yy}^{-1} + \alpha\Sigma_{x | y}^{-1}\alpha^{T} \right)^{-1}\alpha\Sigma_{x | y}^{-1}$


\newpage

## Estimators

### Assume ridge $\beta$, optimize in-sample prediction error

\[ \hat{\beta} = \arg\min_{\beta}\left\{\frac{1}{2} \left\| \mathbb{Y} - \mathbb{X}\beta \right\|_{F}^{2} + \frac{\lambda}{2}\left\| \beta \right\|_{F}^{2}\right\} \]

\begin{align*}
  &\Rightarrow -\mathbb{X}^{T}\left( \mathbb{Y} - \mathbb{X}\hat{\beta} \right) + \lambda\hat{\beta} = 0 \\
  & \\
  &\Rightarrow \hat{\beta} = \left( \mathbb{X}^{T}\mathbb{X} + \lambda I_{p} \right)^{-1}\mathbb{X}^{T}\mathbb{Y} = \mathbb{X}^{T}\left( \mathbb{X}\mathbb{X}^{T} + \lambda I_{n} \right)^{-1}\mathbb{Y}
\end{align*}

\vspace{0.5cm}

### Assume ridge $\beta$, optimize the likelihood for $\beta$

\[ \hat{\beta} = \arg\min_{\beta}\left\{ \frac{1}{n} Tr\left[ \left(\mathbb{Y} - \mathbb{X}\beta \right)^{T}\left( \mathbb{Y} - \mathbb{X}\beta \right)\Sigma_{y | x}^{-1} \right] - \frac{1}{2}log\left| \Sigma_{y | x}^{-1} \right| + \frac{\lambda}{n}\left\| \beta \right\|_{F}^{2} \right\} \]

\begin{align*}
  &\Rightarrow -\frac{2}{n}\mathbb{X}^{T}\left( \mathbb{Y} - \mathbb{X}\hat{\beta} \right)\hat{\Sigma}_{y | x}^{-1} + \frac{2}{n}\lambda\hat{\beta} = 0 \Rightarrow \left( \hat{\Sigma}_{y | x}^{-1} \otimes \mathbb{X}^{T}\mathbb{X} \right)vec\left( \hat{\beta} \right) + \lambda vec\left( \hat{\beta} \right) = vec\left( \mathbb{X}^{T}\mathbb{Y}\hat{\Sigma}_{y | x}^{-1} \right) \\
  & \\
  &\Rightarrow vec\left( \hat{\beta} \right) = \left( \hat{\Sigma}_{y | x}^{-1} \otimes \mathbb{X}^{T}\mathbb{X} + \lambda I_{pr} \right)^{-1}vec\left( \mathbb{X}^{T}\mathbb{Y}\hat{\Sigma}_{y | x}^{-1} \right) \\
\end{align*}

where $\hat{\Sigma}_{y | x} = (\mathbb{Y} - \mathbb{X}\hat{\beta} )^{T}(\mathbb{Y} - \mathbb{X}\hat{\beta})/n$. In order to solve for $\hat{\beta}$, we need to iterate between $\hat{\beta}$ and $\hat{\Sigma}_{y | x}^{-1}$ until convergence.

Note that if $r = 1$ then $\sigma_{y}^{2}$ can be absorbed into $\tilde{\lambda}$ and

\[ \hat{\beta} = \left( \mathbb{X}^{T}\mathbb{X} + \tilde{\lambda}I_{p} \right)^{-1}\mathbb{X}^{T}\mathbb{Y} = \mathbb{X}^{T}\left( \mathbb{X}\mathbb{X}^{T} + \tilde{\lambda}_{n}I_{n} \right)^{-1}\mathbb{Y} \]


\vspace{0.5cm}

### Assume ridge $\Sigma_{xx}^{-1}$, optimize in-sample prediction error

\begin{align*}
  \hat{\Sigma}_{xx}^{-1} &= \arg\min_{\Sigma_{xx}^{-1}}\left\{ \frac{1}{2}\left\| \mathbb{Y} - \mathbb{X}\mathbb{\beta} \right\|_{F}^{2} + \frac{\lambda}{2}\left\| \Sigma_{xx}^{-1} \right\|_{F}^{2} \right\} \\
  & \\
  &= \arg\min_{\Sigma_{xx}^{-1}}\left\{ \frac{1}{2}\left\| \mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right\|_{F}^{2} + \frac{\lambda}{2}\left\| \Sigma_{xx}^{-1} \right\|_{F}^{2} \right\} \\
\end{align*}


\begin{align*}
  \nabla_{\Sigma_{xx}^{-1}}&\left\{ \frac{1}{2}Tr\left[ \left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)^{T}\left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right) \right] + \frac{\lambda}{2}Tr\left[ \Sigma_{xx}^{-1}\Sigma_{xx}^{-1} \right] \right\} \\
  & \\
  &= -\mathbb{X}^{T}\mathbb{Y}\Sigma_{xy}^{T} + \mathbb{X}^{T}\mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy}\Sigma_{xy}^{T} + \lambda\Sigma_{xx}^{-1} \\
  & \\
  &\Rightarrow vec\left( \hat{\Sigma}_{xx}^{-1} \right) = \left(\hat{\Sigma}_{xy}\hat{\Sigma}_{xy}^{T} \otimes \mathbb{X}^{T}\mathbb{X} + \lambda I_{pp} \right)^{-1}vec\left( \mathbb{X}^{T}\mathbb{Y}\hat{\Sigma}_{xy}^{T} \right) \\
\end{align*}

If we use the sample estimate $\hat{\Sigma}_{xy} = \mathbb{X}^{T}\mathbb{Y}/n$ then

\[ vec\left( \hat{\Sigma}_{xx}^{-1} \right) = \left( \mathbb{X}^{T}\mathbb{Y}\mathbb{Y}^{T}\mathbb{X} \otimes \frac{1}{n}\mathbb{X}^{T}\mathbb{X} + \tilde{\lambda}I_{pp} \right)^{-1}vec\left( \mathbb{X}^{T}\mathbb{Y}\mathbb{Y}^{T}\mathbb{X} \right) \]

so that $\hat{\beta} = \hat{\Sigma}_{xx}^{-1}\hat{\Sigma}_{xy} = \hat{\Sigma}_{xx}^{-1}\mathbb{X}^{T}\mathbb{Y}/n$.


\vspace{0.5cm}

### Assume ridge $\Sigma_{xx}^{-1}$, optimize likelihood for $\beta$

\begin{align*}
  \hat{\Sigma}_{xx}^{-1} &= \arg\min_{\Sigma_{xx}^{-1}}\left\{ \frac{1}{n} Tr\left[ \left(\mathbb{Y} - \mathbb{X}\beta \right)^{T}\left( \mathbb{Y} - \mathbb{X}\beta \right)\Sigma_{y | x}^{-1} \right] - \frac{1}{2}log\left| \Sigma_{y | x}^{-1} \right| + \frac{\lambda}{n}\left\| \Sigma_{xx}^{-1} \right\|_{F}^{2} \right\} \\
  & \\
  &= \arg\min_{\Sigma_{xx}^{-1}}\left\{ \frac{1}{n} Tr\left[ \left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)^{T}\left( \mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)\Sigma_{y | x}^{-1} \right] - \frac{1}{2}log\left| \Sigma_{y | x}^{-1} \right| + \frac{\lambda}{n}\left\| \Sigma_{xx}^{-1} \right\|_{F}^{2} \right\} \\
\end{align*}


\begin{align*}
  \nabla_{\Sigma_{xx}^{-1}}&\left\{ \frac{1}{n}Tr\left[ \left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)^{T}\left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)\Sigma_{y | x}^{-1} \right] + \frac{\lambda}{n}Tr\left[ \Sigma_{xx}^{-1}\Sigma_{xx}^{-1} \right] \right\} \\
  & \\
  &= -\frac{2}{n}\mathbb{X}^{T}\mathbb{Y}\Sigma_{y | x}^{-1}\Sigma_{xy}^{T} + \frac{2}{n}\mathbb{X}^{T}\mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy}\Sigma_{y | x}^{-1}\Sigma_{xy}^{T} + \frac{2\lambda}{n}\Sigma_{xx}^{-1} \\
  & \\
  &\Rightarrow vec\left( \hat{\Sigma}_{xx}^{-1} \right) = \left(\hat{\Sigma}_{xy}\hat{\Sigma}_{y | x}^{-1}\hat{\Sigma}_{xy}^{T} \otimes \mathbb{X}^{T}\mathbb{X} + \lambda I_{pp} \right)^{-1}vec\left( \mathbb{X}^{T}\mathbb{Y}\hat{\Sigma}_{y | x}^{-1}\hat{\Sigma}_{xy}^{T} \right) \\
\end{align*}

If we use the sample estimate $\hat{\Sigma}_{xy} = \mathbb{X}^{T}\mathbb{Y}/n$ then

\[ vec\left( \hat{\Sigma}_{xx}^{-1} \right) = \left( \mathbb{X}^{T}\mathbb{Y}\hat{\Sigma}_{y | x}^{-1}\mathbb{Y}^{T}\mathbb{X} \otimes \frac{1}{n}\mathbb{X}^{T}\mathbb{X} + \tilde{\lambda}I_{pp} \right)^{-1}vec\left( \mathbb{X}^{T}\mathbb{Y}\hat{\Sigma}_{y | x}^{-1}\mathbb{Y}^{T}\mathbb{X} \right) \]

where $\hat{\Sigma}_{y | x} = (\mathbb{Y} - \mathbb{X}\hat{\beta} )^{T}(\mathbb{Y} - \mathbb{X}\hat{\beta})/n$ so that in order to solve for $\hat{\beta} = \hat{\Sigma}_{xx}^{-1}\hat{\Sigma}_{xy} = \hat{\Sigma}_{xx}^{-1}\mathbb{X}^{T}\mathbb{Y}/n$, we need to iterate between $\hat{\beta}$ and $\hat{\Sigma}_{y | x}^{-1}$ until convergence.


\vspace{0.5cm}

### Assume ridge $\Sigma_{xx}^{-1}$, optimize likelihood for $\Sigma_{xx}^{-1}$

\[ \hat{\Sigma}_{xx}^{-1} = \arg\min_{\Sigma_{xx}^{-1}}\left\{ Tr\left( S_{xx}\Sigma_{xx}^{-1} \right) - log\left| \Sigma_{xx}^{-1} \right| + \frac{\lambda}{2}\left\| \Sigma_{xx}^{-1} \right\|_{F}^{2} \right\} \]

\begin{align*}
  \nabla_{\Sigma_{xx}^{-1}}&\left\{ Tr\left( S_{xx}\Sigma_{xx}^{-1} \right) - \log\det\left( \Sigma_{xx}^{-1} \right) + \frac{\lambda}{2}\left\| \Sigma_{xx}^{-1} \right\|_{F}^{2} \right\} = S_{xx} - \Sigma_{xx} + \lambda\Sigma_{xx}^{-1} \\
\end{align*}

where $S_{xx} = \mathbb{X}^{T}\mathbb{X}/n$. Set the gradient equal to zero and decompose $\Sigma_{xx}^{-1} = VDV^{T}$ where $D$ is a diagonal matrix with diagonal elements equal to the eigen values of $\Sigma_{xx}^{-1}$ and $V$ is the matrix with corresponding eigen vectors as columns.

\[ S_{xx} = \Sigma_{xx} - \lambda\Sigma_{xx}^{-1} = VD^{-1}V^{T} - \lambda VDV^{T} = V\left(D^{-1} - \lambda D \right)V{^T} \]

This equivalence implies that

\[ \phi_{j}\left( S_{xx} \right) = \frac{1}{\phi_{j}(\Sigma_{xx}^{-1})} - \lambda\phi_{j}\left( \Sigma_{xx}^{-1} \right) \]

where $\phi_{j}(\cdot)$ is the $j$th eigen value.

\begin{align*}
  &\Rightarrow \lambda\phi_{j}^{2}\left( \Sigma_{xx}^{-1} \right) + \phi_{j}\left( S_{xx} \right)\phi_{j}\left( \Sigma_{xx}^{-1} \right) - 1 = 0 \\
  & \\
  &\Rightarrow \phi_{j}\left( \Sigma_{xx}^{-1} \right) = \frac{-\phi_{j}\left( S_{xx} \right) \pm \sqrt{\phi_{j}^{2}\left( S_{xx} \right) + 4\lambda}}{2\lambda}
\end{align*}

In summary, if we decompose $S_{xx} = VQV^{T}$ then

\[ \hat{\Sigma}_{xx}^{-1} = \frac{1}{2\lambda}V\left[ -Q + \left( Q^{2} + 4\lambda I_{p} \right)^{1/2} \right]V^{T} \]


so that $\hat{\beta} = \hat{\Sigma}_{xx}^{-1}\Sigma_{xy} = \hat{\Sigma}_{xx}^{-1}\mathbb{X}^{T}\mathbb{Y}/n$.


\vspace{0.5cm}

### Assume ridge $\Sigma_{xy}$, optimize in-sample prediction error

\begin{align*}
  \hat{\Sigma}_{xy} &= \arg\min_{\Sigma_{xy}}\left\{ \frac{1}{2}\left\| \mathbb{Y} - \mathbb{X}\mathbb{\beta} \right\|_{F}^{2} + \frac{\lambda}{2}\left\| \Sigma_{xy} \right\|_{F}^{2} \right\} \\
  & \\
  &= \arg\min_{\Sigma_{xy}}\left\{ \frac{1}{2}\left\| \mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right\|_{F}^{2} + \frac{\lambda}{2}\left\| \Sigma_{xy} \right\|_{F}^{2} \right\} \\
\end{align*}


\begin{align*}
  \nabla_{\Sigma_{xy}}&\left\{ \frac{1}{2}Tr\left[ \left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)^{T}\left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right) \right] + \frac{\lambda}{2}Tr\left[ \Sigma_{xy}\Sigma_{xy} \right] \right\} \\
  & \\
  &= -\Sigma_{xx}^{-1}\mathbb{X}^{T}\mathbb{Y} + \Sigma_{xx}^{-1}\mathbb{X}^{T}\mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} + \lambda\Sigma_{xy} \\
  & \\
  &\Rightarrow \hat{\Sigma}_{xy} = \left(\hat{\Sigma}_{xx}^{-1}\mathbb{X}^{T}\mathbb{X}\hat{\Sigma}_{xx}^{-1} + \lambda I_{p} \right)^{-1}\hat{\Sigma}_{xx}^{-1}\mathbb{X}^{T}\mathbb{Y} \\
\end{align*}

If we use the sample estimate $\hat{\Sigma}_{xx} = \mathbb{X}^{T}\mathbb{X}/n$ (assuming $\mathbb{X}^{T}\mathbb{X}$ is positive definite) then

\[ \hat{\Sigma}_{xy} = \left[\left(\mathbb{X}^{T}\mathbb{X} \right)^{-1} + \tilde{\lambda}I_{p} \right]^{-1}\left(\mathbb{X}^{T}\mathbb{X} \right)^{-1}\mathbb{X}^{T}\mathbb{Y}/n = \left( I_{p} + \tilde{\lambda}\mathbb{X}^{T}\mathbb{X} \right)^{-1}\mathbb{X}^{T}\mathbb{Y}/n \]

so that

\begin{align*}
  \hat{\beta} &= \left( \mathbb{X}^{T}\mathbb{X} \right)^{-1}\left[ \left( \mathbb{X}^{T}\mathbb{X} \right)^{-1} + \tilde{\lambda}I_{p} \right]^{-1}\left( \mathbb{X}^{T}\mathbb{X} \right)^{-1}\mathbb{X}^{T}\mathbb{Y} \\
  & \\
  &= \left[ \mathbb{X}^{T}\mathbb{X}\left( I_{p} + \tilde{\lambda}\mathbb{X}^{T}\mathbb{X} \right) \right]^{-1}\mathbb{X}^{T}\mathbb{X} = \left( \mathbb{X}^{T}\mathbb{X} + \tilde{\lambda}\mathbb{X}^{T}\mathbb{X}\mathbb{X}^{T}\mathbb{X} \right)^{-1}\mathbb{X}^{T}\mathbb{Y}
\end{align*}


\vspace{0.5cm}

### Assume ridge $\Sigma_{xy}$, optimize likelihood for $\beta$

\begin{align*}
  \hat{\Sigma}_{xy} &= \arg\min_{\Sigma_{xy}}\left\{ \frac{1}{n} Tr\left[ \left(\mathbb{Y} - \mathbb{X}\beta \right)^{T}\left( \mathbb{Y} - \mathbb{X}\beta \right)\Sigma_{y | x}^{-1} \right] - \frac{1}{2}log\left| \Sigma_{y | x}^{-1} \right| + \frac{\lambda}{n}\left\| \Sigma_{xy} \right\|_{F}^{2} \right\} \\
  & \\
  &= \arg\min_{\Sigma_{xy}}\left\{ \frac{1}{n} Tr\left[ \left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)^{T}\left( \mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)\Sigma_{y | x}^{-1} \right] - \frac{1}{2}log\left| \Sigma_{y | x}^{-1} \right| + \frac{\lambda}{n}\left\| \Sigma_{xy} \right\|_{F}^{2} \right\} \\
\end{align*}


\begin{align*}
  \nabla_{\Sigma_{xy}}&\left\{ \frac{1}{n}Tr\left[ \left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)^{T}\left(\mathbb{Y} - \mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy} \right)\Sigma_{y | x}^{-1} \right] + \frac{\lambda}{n}Tr\left[ \Sigma_{xy}^{T}\Sigma_{xy} \right] \right\} \\
  & \\
  &= -\frac{2}{n}\Sigma_{xx}^{-1}\mathbb{X}^{T}\mathbb{Y}\Sigma_{y | x}^{-1} + \frac{2}{n}\Sigma_{xx}^{-1}\mathbb{X}^{T}\mathbb{X}\Sigma_{xx}^{-1}\Sigma_{xy}\Sigma_{y | x}^{-1} + \frac{2\lambda}{n}\Sigma_{xy} \\
\end{align*}

If we use the sample estimate $\hat{\Sigma}_{xx} = \mathbb{X}^{T}\mathbb{X}/n$ (assuming $\mathbb{X}^{T}\mathbb{X}$ is positive definite) then

\begin{align*}
  vec\left( \hat{\Sigma}_{xy} \right) &= \left[\hat{\Sigma}_{y | x}^{-1} \otimes n\left( \mathbb{X}^{T}\mathbb{X} \right)^{-1} + \tilde{\lambda} I_{rp} \right]^{-1}vec\left[ \left( \mathbb{X}^{T}\mathbb{X} \right)^{-1}\mathbb{X}^{T}\mathbb{Y}\hat{\Sigma}_{y | x}^{-1} \right] \\
  & \\
  &= \left[ \Sigma_{y | x}^{-1} \otimes \left( \tilde{\lambda}\mathbb{X}^{T}\mathbb{X} + I_{p} \right) \right]^{-1}vec\left[ \mathbb{X}^{T}\mathbb{Y}\Sigma_{y | x}^{-1} \right]
\end{align*}

where $\hat{\Sigma}_{y | x} = (\mathbb{Y} - \mathbb{X}\hat{\beta} )^{T}(\mathbb{Y} - \mathbb{X}\hat{\beta})/n$ so that in order to solve for $\hat{\beta} = \hat{\Sigma}_{xx}^{-1}\hat{\Sigma}_{xy} = n\left( \mathbb{X}^{T}\mathbb{X} \right)^{-1}\hat{\Sigma}_{xy}$, we need to iterate between $\hat{\beta}$ and $\hat{\Sigma}_{y | x}^{-1}$ until convergence.


\vspace{0.5cm}

### Assume ridge $\Sigma_{x | y}^{-1}$, optimize likelihood for $\Sigma_{x | y}^{-1}$

\[ \hat{\Sigma}_{x | y}^{-1} = \arg\min_{\Sigma_{x | y}^{-1}}\left\{ Tr\left( S_{x | y}\Sigma_{x | y}^{-1} \right) - log\left| \Sigma_{x | y}^{-1} \right| + \frac{\lambda}{2}\left\| \Sigma_{x | y}^{-1} \right\|_{F}^{2} \right\} \]

\begin{align*}
  \nabla_{\Sigma_{x | y}^{-1}}&\left\{ Tr\left( S_{x | y}\Sigma_{x | y}^{-1} \right) - \log\det\left( \Sigma_{x | y}^{-1} \right) + \frac{\lambda}{2}\left\| \Sigma_{x | y}^{-1} \right\|_{F}^{2} \right\} = S_{x | y} - \Sigma_{x | y} + \lambda\Sigma_{x | y}^{-1} \\
\end{align*}

where $S_{x | y} = \left( \mathbb{X} - \mathbb{Y}\hat{\alpha} \right)^{T}\left( \mathbb{X} - \mathbb{Y}\hat{\alpha} \right)/n$ and $\hat{\alpha} = \left( \mathbb{Y}^{T}\mathbb{Y} \right)^{-1}\mathbb{Y}^{T}\mathbb{X}$. Following the derivations in section (3.5), if we decompose $S_{x | y} = VQV^{T}$ then

\[ \hat{\Sigma}_{x | y}^{-1} = \frac{1}{2\lambda}V\left[ -Q + \left( Q^{2} + 4\lambda I_{p} \right)^{1/2} \right]V^{T} \]

Using the Woodbury Identity, we find that

\[ \hat{\beta} = \hat{\Sigma}_{x | y}^{-1}\Sigma_{xy}\left( \Sigma_{yy} + \Sigma_{xy}^{T}\hat{\Sigma}_{x | y}^{-1}\Sigma_{xy} \right)^{-1}\Sigma_{yy} = \hat{\Sigma}_{x | y}^{-1}\hat{\alpha}^{T}\left( \Sigma_{yy}^{-1} + \hat{\alpha}\hat{\Sigma}_{x | y}^{-1}\hat{\alpha} \right)^{-1} \]


\vspace{0.5cm}

### Assume ridge $\alpha$, optimize in-sample prediction error for $\alpha$

\[ \hat{\alpha} = \arg\min_{\alpha}\left\{\frac{1}{2} \left\| \mathbb{X} - \mathbb{Y}\alpha \right\|_{F}^{2} + \frac{\lambda}{2}\left\| \alpha \right\|_{F}^{2}\right\} \]

\begin{align*}
  &\Rightarrow -\mathbb{Y}^{T}\left( \mathbb{X} - \mathbb{Y}\hat{\alpha} \right) + \lambda\hat{\alpha} = 0 \\
  & \\
  &\Rightarrow \hat{\alpha} = \left( \mathbb{Y}^{T}\mathbb{Y} + \lambda I_{r} \right)^{-1}\mathbb{Y}^{T}\mathbb{X} = \mathbb{Y}^{T}\left( \mathbb{Y}\mathbb{Y}^{T} + \lambda I_{n} \right)^{-1}\mathbb{X}
\end{align*}

Using the Woodbury Identity, we find that

\[ \hat{\beta} = \Sigma_{x | y}^{-1}\hat{\alpha}^{T}\left( \Sigma_{yy}^{-1} + \hat{\alpha}\Sigma_{x | y}^{-1}\hat{\alpha}^{T} \right)^{-1} \]


\vspace{0.5cm}

### Assume ridge $\alpha$, optimize likelihood for $\alpha$

\[ \hat{\alpha} = \arg\min_{\alpha}\left\{ \frac{1}{n} Tr\left[ \left(\mathbb{X} - \mathbb{Y}\alpha \right)^{T}\left( \mathbb{X} - \mathbb{Y}\alpha \right)\Sigma_{x | y}^{-1} \right] - \frac{1}{2}log\left| \Sigma_{x | y}^{-1} \right| + \frac{\lambda}{n}\left\| \alpha \right\|_{F}^{2} \right\} \]

\begin{align*}
  &\Rightarrow -\frac{2}{n}\mathbb{Y}^{T}\left( \mathbb{X} - \mathbb{Y}\hat{\alpha} \right)\hat{\Sigma}_{x | y}^{-1} + \frac{2}{n}\lambda\hat{\alpha} = 0 \Rightarrow \left( \hat{\Sigma}_{x | y}^{-1} \otimes \mathbb{Y}^{T}\mathbb{Y} \right)vec\left( \hat{\alpha} \right) + \lambda vec\left( \hat{\alpha} \right) = vec\left( \mathbb{Y}^{T}\mathbb{X}\hat{\Sigma}_{x | y}^{-1} \right) \\
  & \\
  &\Rightarrow vec\left( \hat{\alpha} \right) = \left( \hat{\Sigma}_{x | y}^{-1} \otimes \mathbb{Y}^{T}\mathbb{Y} + \lambda I_{pr} \right)^{-1}vec\left( \mathbb{Y}^{T}\mathbb{X}\hat{\Sigma}_{x | y}^{-1} \right) \\
\end{align*}

where $\hat{\Sigma}_{x | y} = (\mathbb{X} - \mathbb{Y}\hat{\alpha} )^{T}(\mathbb{X} - \mathbb{Y}\hat{\alpha})/n$. In order to solve for $\hat{\alpha}$, we need to iterate between $\hat{\alpha}$ and $\hat{\Sigma}_{x | y}^{-1}$ until convergence. Again, using the Woodbury Identity, we find that

\[ \hat{\beta} = \hat{\Sigma}_{x | y}^{-1}\hat{\alpha}^{T}\left( \Sigma_{yy}^{-1} + \hat{\alpha}\hat{\Sigma}_{x | y}^{-1}\hat{\alpha}^{T} \right)^{-1} \]
